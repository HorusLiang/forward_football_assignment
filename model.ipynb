{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('generated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "X = df.loc[:, ~df.columns.isin([\"isSucceeded\"])]\n",
    "y = df[\"isSucceeded\"]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_score(X,y):\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    # Create an instance of the DummyClassifier class\n",
    "    dummy_classifier = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "    # Fit the DummyClassifier instance to the training data\n",
    "    dummy_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the performance of the DummyClassifier on the test data\n",
    "    accuracy = dummy_classifier.score(X_test, y_test)\n",
    "\n",
    "    print(\"accuracy=\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.7377622377622378\n"
     ]
    }
   ],
   "source": [
    "get_dummy_score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Create an instance of the RandomOverSampler class\n",
    "random_over_sampler = RandomOverSampler()\n",
    "\n",
    "# Create an instance of the SMOTE class\n",
    "smote = SMOTE()\n",
    "\n",
    "# Fit the RandomOverSampler to the data\n",
    "X_resampled, y_resampled = random_over_sampler.fit_resample(X, y)\n",
    "\n",
    "# Fit the SMOTE to the data\n",
    "X,y = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.49754901960784315\n"
     ]
    }
   ],
   "source": [
    "get_dummy_score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# insight: classifiers are just above the dummy model or even above, try to extract more features\n",
    "\n",
    "# Define a dictionary of classification models\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(),\n",
    "    \"support_vector_machine\": SVC(),\n",
    "    \"k_nearest_neighbors\": KNeighborsClassifier(),\n",
    "    \"decision_tree\": DecisionTreeClassifier(),\n",
    "    \"random_forest\": RandomForestClassifier(),\n",
    "    \"ada_boost\": AdaBoostClassifier(),\n",
    "    \"gradient_boosting\": GradientBoostingClassifier(),\n",
    "    \"xg_boost\": XGBClassifier(),\n",
    "    \"bagging\": BaggingClassifier(),\n",
    "    \"extra_trees\": ExtraTreesClassifier(),\n",
    "    \"mlp\": MLPClassifier(),\n",
    "    \"gaussian_process\": GaussianProcessClassifier(),\n",
    "    \"quadratic_discriminant_analysis\": QuadraticDiscriminantAnalysis()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression: 0.3015271758503593\n",
      "support_vector_machine: 0.37852948349937143\n",
      "k_nearest_neighbors: 0.4210108628355941\n",
      "decision_tree: 0.5043601433368979\n",
      "random_forest: 0.4541922290388548\n",
      "ada_boost: 0.39414832742350053\n",
      "gradient_boosting: 0.3996904373276299\n",
      "xg_boost: 0.4412937843567663\n",
      "bagging: 0.4951783268606594\n",
      "extra_trees: 0.5080561340312564\n",
      "mlp: 0.500611620795107\n",
      "gaussian_process: 0.4712331851184781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quadratic_discriminant_analysis: 0.6214686403632201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# Loop through the models and evaluate each one\n",
    "for name, model in models.items():\n",
    "    # Evaluate the model using cross-validation\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "    # Print the average accuracy\n",
    "    print(f\"{name}: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "    'min_samples_split': [10,20,30],\n",
    "    'min_samples_leaf': [5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create an instance of the Random Forest classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Create an instance of the RandomizedSearchCV class\n",
    "random_search = RandomizedSearchCV(classifier, param_grid)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7539416226154907"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best model\n",
    "classifier = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=RandomForestClassifier(max_depth=4,\n",
       "                                                 min_samples_leaf=5,\n",
       "                                                 min_samples_split=20,\n",
       "                                                 n_estimators=1000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestClassifier(max_depth=4,\n",
       "                                                 min_samples_leaf=5,\n",
       "                                                 min_samples_split=20,\n",
       "                                                 n_estimators=1000))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=4, min_samples_leaf=5, min_samples_split=20,\n",
       "                       n_estimators=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=4, min_samples_leaf=5, min_samples_split=20,\n",
       "                       n_estimators=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(max_depth=4,\n",
       "                                                 min_samples_leaf=5,\n",
       "                                                 min_samples_split=20,\n",
       "                                                 n_estimators=1000))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# Create an instance of the SelectFromModel class\n",
    "feature_selector = SelectFromModel(classifier)\n",
    "\n",
    "# Fit the SelectFromModel instance to the data\n",
    "feature_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected features\n",
    "selected_features = feature_selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 30, 'min_samples_leaf': 5, 'max_depth': 4}\n",
      "0.7670956868152915\n"
     ]
    }
   ],
   "source": [
    "# tempt !!!\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create an instance of the Random Forest classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Create an instance of the RandomizedSearchCV class\n",
    "random_search = RandomizedSearchCV(classifier, param_grid)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(selected_features, y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(random_search.best_params_)\n",
    "\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 3}\n",
      "0.4285341738428922\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Create an instance of the RandomOverSampler class\n",
    "random_over_sampler = RandomOverSampler()\n",
    "\n",
    "# Create an instance of the SMOTE class\n",
    "smote = SMOTE()\n",
    "\n",
    "# Fit the RandomOverSampler to the data\n",
    "X_resampled, y_resampled = random_over_sampler.fit_resample(X, y)\n",
    "\n",
    "# Fit the SMOTE to the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create an instance of the Random Forest classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Create an instance of the RandomizedSearchCV class\n",
    "random_search = RandomizedSearchCV(classifier, param_grid)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print the best parameters\n",
    "print(random_search.best_params_)\n",
    "\n",
    "print(random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.47549019607843135\n"
     ]
    }
   ],
   "source": [
    "get_dummy_score(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('intro_to_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2d8aa6afe6024b62f6f9fc5a6755ecc5ab5ed657f1dbb49859cc1c431d03a86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
