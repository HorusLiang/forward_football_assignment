{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('generated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"receiverId\"]=df[\"receiverId\"].fillna(0) # a sign bit, in order to distinguish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ~df.columns.isin([\"isSucceeded\"])]\n",
    "y = df[\"isSucceeded\"]\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "def time_series_split(X,y):\n",
    "    ts_split = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "    # Define the features and target variable\n",
    "    \n",
    "    for train_index, test_index in ts_split.split(df):\n",
    "    # Get the training and validation sets\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train,y_test=y[train_index],y[test_index]\n",
    "\n",
    "        df_train, df_test = df.iloc[train_index,:], df.iloc[test_index,:]\n",
    "    return X_train, X_test, y_train, y_test,df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: some feature are generated for example grouby should seperate from train and test dataset\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test,df_train, df_test= time_series_split(X, y)\n",
    "\n",
    "# not so good to split time series data like this way->done, using TimeSeriesSplit->done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/p_92kz8j46lgdkjkzzrm9wm40000gn/T/ipykernel_39605/1650385110.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['succeed_rate_rec']=df['receiverId'].map(lambda x:data_dict[x])\n",
      "/var/folders/ws/p_92kz8j46lgdkjkzzrm9wm40000gn/T/ipykernel_39605/1650385110.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['succeed_rate_rec']=df['receiverId'].map(lambda x:use_lambda(x))\n"
     ]
    }
   ],
   "source": [
    "# the receivedId also have an influence, but if has a receiverId, then the pass rate is 100%, so calcuated pass rate for each receiverId is useless as below\n",
    "# useless -> done\n",
    "\n",
    "# def added_X_train_test_receiver(df_train,X_train,X_test):\n",
    "#     data_dict=df_train.groupby(['receiverId']).mean('isSucceeded')['isSucceeded'].to_dict()\n",
    "\n",
    "#     def add_receiver_rate_train(df): # note player_id and success_rate is one vs one, have no information, but will have information on the test data!!!\n",
    "#         df['succeed_rate_rec']=df['receiverId'].map(lambda x:data_dict[x])\n",
    "#         return df\n",
    "\n",
    "#     def use_lambda(x):\n",
    "#         import math\n",
    "#         if x==0: return np.mean(list(data_dict.values()))\n",
    "#         elif x in data_dict.keys(): # althrough keys() has x==0\n",
    "#             return data_dict[x]\n",
    "#         else: return np.mean(list(data_dict.values()))\n",
    "#     def add_receiver_rate_test(df):\n",
    "#         df['succeed_rate_rec']=df['receiverId'].map(lambda x:use_lambda(x))\n",
    "#         return df\n",
    "\n",
    "#     return add_receiver_rate_train(X_train),add_receiver_rate_test(X_test)\n",
    "    \n",
    "# X_train,X_test=added_X_train_test_receiver(df_train,X_train,X_test)\n",
    "# X_train.succeed_rate_rec.unique() # for test the conclusion above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/p_92kz8j46lgdkjkzzrm9wm40000gn/T/ipykernel_39605/3466680499.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pair_count']=df.apply(use_lambda,axis=1)\n",
      "/var/folders/ws/p_92kz8j46lgdkjkzzrm9wm40000gn/T/ipykernel_39605/3466680499.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pair_count']=df.apply(use_lambda,axis=1)\n"
     ]
    }
   ],
   "source": [
    "# count pair (receiverId and playId)\n",
    "\n",
    "def added_X_train_test_pair(df_train,X_train,X_test):\n",
    "    data_dict=df_train.groupby(['receiverId','Player_id']).sum('isSucceeded')['isSucceeded'].to_dict()\n",
    "\n",
    "    def use_lambda(df):\n",
    "        import math\n",
    "        if (df[\"receiverId\"],df['Player_id']) in data_dict.keys():\n",
    "            return data_dict[(df[\"receiverId\"],df['Player_id'])]\n",
    "        return 0\n",
    "\n",
    "    def add_pair_rate_train(df): \n",
    "        df['pair_count']=df.apply(use_lambda,axis=1)\n",
    "        return df\n",
    "\n",
    "    def add_pair_rate_test(df):\n",
    "        df['pair_count']=df.apply(use_lambda,axis=1)\n",
    "        return df\n",
    "\n",
    "    return add_pair_rate_train(X_train),add_pair_rate_test(X_test)\n",
    "    \n",
    "X_train,X_test=added_X_train_test_pair(df_train,X_train,X_test)\n",
    "\n",
    "# X_test.pair_count.sum() # result is more than 200, so a good idea at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>posX_passer</th>\n",
       "      <th>posY_passer</th>\n",
       "      <th>received_PosX</th>\n",
       "      <th>received_PosY</th>\n",
       "      <th>isForward</th>\n",
       "      <th>isSucceeded</th>\n",
       "      <th>receiverId</th>\n",
       "      <th>Player_id</th>\n",
       "      <th>Team</th>\n",
       "      <th>...</th>\n",
       "      <th>pass_day</th>\n",
       "      <th>pass_hour</th>\n",
       "      <th>pass_minute</th>\n",
       "      <th>pass_second</th>\n",
       "      <th>start_day</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_minute</th>\n",
       "      <th>time_process_hour</th>\n",
       "      <th>time_process_minute</th>\n",
       "      <th>time_process_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95583.0</td>\n",
       "      <td>95582</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95601.0</td>\n",
       "      <td>95582</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95597.0</td>\n",
       "      <td>95582</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>55</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95587.0</td>\n",
       "      <td>95582</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>53</td>\n",
       "      <td>83</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95579.0</td>\n",
       "      <td>95582</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1137</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95583.0</td>\n",
       "      <td>95597</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1138</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95601.0</td>\n",
       "      <td>95597</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1139</td>\n",
       "      <td>35</td>\n",
       "      <td>48</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95617.0</td>\n",
       "      <td>95597</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1140</td>\n",
       "      <td>47</td>\n",
       "      <td>58</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95603.0</td>\n",
       "      <td>95597</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>1141</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95986.0</td>\n",
       "      <td>95597</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1142 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  posX_passer  posY_passer  received_PosX  received_PosY  \\\n",
       "0              0           32           58             26             55   \n",
       "1              1           16           23             20             29   \n",
       "2              2           92           56             68             52   \n",
       "3              3           72           55             76             62   \n",
       "4              4           74           53             83             50   \n",
       "...          ...          ...          ...            ...            ...   \n",
       "1137        1137            3            8              9              9   \n",
       "1138        1138            4           12             14             47   \n",
       "1139        1139           35           48             35             40   \n",
       "1140        1140           47           58             47             59   \n",
       "1141        1141           31           32             34             34   \n",
       "\n",
       "      isForward  isSucceeded  receiverId  Player_id  Team  ...  pass_day  \\\n",
       "0             1            1     95583.0      95582     0  ...         5   \n",
       "1             0            1     95601.0      95582     0  ...         5   \n",
       "2             1            1     95597.0      95582     0  ...         5   \n",
       "3             0            1     95587.0      95582     0  ...         5   \n",
       "4             0            1     95579.0      95582     0  ...         5   \n",
       "...         ...          ...         ...        ...   ...  ...       ...   \n",
       "1137          0            1     95583.0      95597     1  ...        12   \n",
       "1138          0            1     95601.0      95597     1  ...        12   \n",
       "1139          0            1     95617.0      95597     1  ...        12   \n",
       "1140          0            1     95603.0      95597     1  ...        12   \n",
       "1141          0            1     95986.0      95597     1  ...        12   \n",
       "\n",
       "      pass_hour  pass_minute  pass_second  start_day  start_hour  \\\n",
       "0            11           39           15          5          11   \n",
       "1            11           39           59          5          11   \n",
       "2            11           41           47          5          11   \n",
       "3            11           45           55          5          11   \n",
       "4            11           46            1          5          11   \n",
       "...         ...          ...          ...        ...         ...   \n",
       "1137         12           51           49         12          12   \n",
       "1138         12           51           52         12          12   \n",
       "1139         12           52           37         12          12   \n",
       "1140         12           53           57         12          12   \n",
       "1141         12           55           38         12          12   \n",
       "\n",
       "      start_minute  time_process_hour  time_process_minute  \\\n",
       "0               36                  0                    3   \n",
       "1               36                  0                    3   \n",
       "2               36                  0                    5   \n",
       "3               36                  0                    9   \n",
       "4               36                  0                    9   \n",
       "...            ...                ...                  ...   \n",
       "1137             6                  0                   45   \n",
       "1138             6                  0                   45   \n",
       "1139             6                  0                   46   \n",
       "1140             6                  0                   47   \n",
       "1141             6                  0                   49   \n",
       "\n",
       "      time_process_second  \n",
       "0                       2  \n",
       "1                      46  \n",
       "2                      34  \n",
       "3                      42  \n",
       "4                      48  \n",
       "...                   ...  \n",
       "1137                   36  \n",
       "1138                   39  \n",
       "1139                   24  \n",
       "1140                   44  \n",
       "1141                   25  \n",
       "\n",
       "[1142 rows x 33 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # notice Unnamed:0 is to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict=df_train.groupby(['Player_id']).mean('isSucceeded')['isSucceeded'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_success_rate_train(df): # note player_id and success_rate is one vs one, have no information, but will have information on the test data!!!\n",
    "    df['succeed_rate']=df['Player_id'].map(lambda x:data_dict[x])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_lambda(x):\n",
    "    import math\n",
    "    if x in data_dict.keys():\n",
    "        return data_dict[x]\n",
    "    return np.mean(list(data_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_success_rate_test(df):\n",
    "    df['succeed_rate']=df['Player_id'].map(lambda x:use_lambda(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/p_92kz8j46lgdkjkzzrm9wm40000gn/T/ipykernel_39605/1914586036.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['succeed_rate']=df['Player_id'].map(lambda x:data_dict[x])\n",
      "/var/folders/ws/p_92kz8j46lgdkjkzzrm9wm40000gn/T/ipykernel_39605/2144164121.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['succeed_rate']=df['Player_id'].map(lambda x:use_lambda(x))\n"
     ]
    }
   ],
   "source": [
    "X_train=add_success_rate_train(X_train)\n",
    "X_test=add_success_rate_test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate feature based on received_id and also zone\n",
    "zone_dict=df_train.groupby(['Player_id','Zone']).mean('isSucceeded')['isSucceeded'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['zone_rate']=df[['Player_id','Zone']].map(lambda x:zone_dict[(x[0],x[1])]) this can't work, map can only used in series, use apply instead\n",
    "def use_zone_lambda_train(df):\n",
    "    return zone_dict[(df[\"Player_id\"],df['Zone'])]\n",
    "def add_zone_rate_train(df): # note player_id and success_rate is one vs one, have no information, but will have information on the test data!!!\n",
    "    df['zone_rate']=df[['Player_id','Zone']].apply(use_zone_lambda_train,axis=1)\n",
    "    return df\n",
    "\n",
    "def use_zone_lambda_test(df):\n",
    "    import math\n",
    "    if (df[\"Player_id\"],df['Zone']) in zone_dict.keys():\n",
    "        return zone_dict[(df[\"Player_id\"],df['Zone'])]\n",
    "    else:\n",
    "        sub_dict = {key: value for key, value in zone_dict.items() if key[1]== df['Zone']}\n",
    "        return np.mean(list(sub_dict.values()))\n",
    "def add_zone_rate_test(df):\n",
    "    df['zone_rate']=df[['Player_id','Zone']].apply(use_zone_lambda_test,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/p_92kz8j46lgdkjkzzrm9wm40000gn/T/ipykernel_39605/3936894386.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['zone_rate']=df[['Player_id','Zone']].apply(use_zone_lambda_train,axis=1)\n",
      "/var/folders/ws/p_92kz8j46lgdkjkzzrm9wm40000gn/T/ipykernel_39605/3936894386.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['zone_rate']=df[['Player_id','Zone']].apply(use_zone_lambda_test,axis=1)\n"
     ]
    }
   ],
   "source": [
    "X_train=add_zone_rate_train(X_train)\n",
    "X_test=add_zone_rate_test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_score(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "    # Create an instance of the DummyClassifier class\n",
    "    dummy_classifier = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "    # Fit the DummyClassifier instance to the training data\n",
    "    dummy_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the performance of the DummyClassifier on the test data\n",
    "    accuracy = dummy_classifier.score(X_test, y_test)\n",
    "\n",
    "    print(\"accuracy=\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.718421052631579\n"
     ]
    }
   ],
   "source": [
    "get_dummy_score(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "def over_sampler(X,y):\n",
    "    # Create an instance of the RandomOverSampler class\n",
    "    random_over_sampler = RandomOverSampler()\n",
    "\n",
    "    # Create an instance of the SMOTE class\n",
    "    smote = SMOTE()\n",
    "\n",
    "    # Fit the RandomOverSampler to the data\n",
    "    X_resampled, y_resampled = random_over_sampler.fit_resample(X, y)\n",
    "\n",
    "    # Fit the SMOTE to the data\n",
    "    X,y = smote.fit_resample(X_resampled, y_resampled)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=over_sampler(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.718421052631579\n"
     ]
    }
   ],
   "source": [
    "get_dummy_score(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(['receiverId'],axis=1)\n",
    "X_test=X_test.drop(['receiverId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# insight: classifiers are just above the dummy model or even above, try to extract more features\n",
    "\n",
    "# Define a dictionary of classification models\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(),\n",
    "    \"support_vector_machine\": SVC(),\n",
    "    \"k_nearest_neighbors\": KNeighborsClassifier(),\n",
    "    \"decision_tree\": DecisionTreeClassifier(),\n",
    "    \"random_forest\": RandomForestClassifier(),\n",
    "    \"ada_boost\": AdaBoostClassifier(),\n",
    "    \"gradient_boosting\": GradientBoostingClassifier(),\n",
    "    \"xg_boost\": XGBClassifier(),\n",
    "    \"bagging\": BaggingClassifier(),\n",
    "    \"extra_trees\": ExtraTreesClassifier(),\n",
    "    \"mlp\": MLPClassifier(),\n",
    "    \"gaussian_process\": GaussianProcessClassifier(),\n",
    "    \"quadratic_discriminant_analysis\": QuadraticDiscriminantAnalysis()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6026315789473684\n",
      "support_vector_machine :\n",
      "0.718421052631579\n",
      "k_nearest_neighbors :\n",
      "0.6921052631578948\n",
      "decision_tree :\n",
      "0.718421052631579\n",
      "random_forest :\n",
      "0.7605263157894737\n",
      "ada_boost :\n",
      "0.5026315789473684\n",
      "gradient_boosting :\n",
      "0.718421052631579\n",
      "xg_boost :\n",
      "0.718421052631579\n",
      "bagging :\n",
      "0.718421052631579\n",
      "extra_trees :\n",
      "0.718421052631579\n",
      "mlp :\n",
      "0.718421052631579\n",
      "gaussian_process :\n",
      "0.29210526315789476\n",
      "quadratic_discriminant_analysis :\n",
      "0.718421052631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/horus_liang/opt/anaconda3/envs/intro_to_ds/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# Loop through the models and evaluate each one\n",
    "for name, model in models.items():\n",
    "\n",
    "    print(name,\":\")\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "    'min_samples_split': [10,20,30],\n",
    "    'min_samples_leaf': [5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create an instance of the Random Forest classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Create an instance of the RandomizedSearchCV class\n",
    "random_search = RandomizedSearchCV(classifier, param_grid)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7539416226154907"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best model\n",
    "classifier = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=RandomForestClassifier(max_depth=4,\n",
       "                                                 min_samples_leaf=5,\n",
       "                                                 min_samples_split=20,\n",
       "                                                 n_estimators=1000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestClassifier(max_depth=4,\n",
       "                                                 min_samples_leaf=5,\n",
       "                                                 min_samples_split=20,\n",
       "                                                 n_estimators=1000))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=4, min_samples_leaf=5, min_samples_split=20,\n",
       "                       n_estimators=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=4, min_samples_leaf=5, min_samples_split=20,\n",
       "                       n_estimators=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(max_depth=4,\n",
       "                                                 min_samples_leaf=5,\n",
       "                                                 min_samples_split=20,\n",
       "                                                 n_estimators=1000))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# Create an instance of the SelectFromModel class\n",
    "feature_selector = SelectFromModel(classifier)\n",
    "\n",
    "# Fit the SelectFromModel instance to the data\n",
    "feature_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected features\n",
    "selected_features = feature_selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 30, 'min_samples_leaf': 5, 'max_depth': 4}\n",
      "0.7670956868152915\n"
     ]
    }
   ],
   "source": [
    "# tempt !!!\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create an instance of the Random Forest classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Create an instance of the RandomizedSearchCV class\n",
    "random_search = RandomizedSearchCV(classifier, param_grid)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(selected_features, y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(random_search.best_params_)\n",
    "\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 3}\n",
      "0.4285341738428922\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Create an instance of the RandomOverSampler class\n",
    "random_over_sampler = RandomOverSampler()\n",
    "\n",
    "# Create an instance of the SMOTE class\n",
    "smote = SMOTE()\n",
    "\n",
    "# Fit the RandomOverSampler to the data\n",
    "X_resampled, y_resampled = random_over_sampler.fit_resample(X, y)\n",
    "\n",
    "# Fit the SMOTE to the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create an instance of the Random Forest classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Create an instance of the RandomizedSearchCV class\n",
    "random_search = RandomizedSearchCV(classifier, param_grid)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print the best parameters\n",
    "print(random_search.best_params_)\n",
    "\n",
    "print(random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.47549019607843135\n"
     ]
    }
   ],
   "source": [
    "get_dummy_score(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('intro_to_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2d8aa6afe6024b62f6f9fc5a6755ecc5ab5ed657f1dbb49859cc1c431d03a86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
